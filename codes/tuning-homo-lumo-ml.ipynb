{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-jacob",
   "metadata": {},
   "source": [
    "# Model tuning\n",
    "\n",
    "Tuning models hyperparameters\n",
    "\n",
    "- Model: xgboost and random forest model\n",
    "- Tuner: optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "republican-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/maccs_data.csv'\n",
    "\n",
    "data = pd.read_csv(PATH)\n",
    "data['gap'] = data['lumo'] - data['homo']\n",
    "data = data.drop(['smile', 'homo', 'lumo'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accepting-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maccs_1</th>\n",
       "      <th>maccs_2</th>\n",
       "      <th>maccs_3</th>\n",
       "      <th>maccs_4</th>\n",
       "      <th>maccs_5</th>\n",
       "      <th>maccs_6</th>\n",
       "      <th>maccs_7</th>\n",
       "      <th>maccs_8</th>\n",
       "      <th>maccs_9</th>\n",
       "      <th>maccs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>maccs_158</th>\n",
       "      <th>maccs_159</th>\n",
       "      <th>maccs_160</th>\n",
       "      <th>maccs_161</th>\n",
       "      <th>maccs_162</th>\n",
       "      <th>maccs_163</th>\n",
       "      <th>maccs_164</th>\n",
       "      <th>maccs_165</th>\n",
       "      <th>maccs_166</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   maccs_1  maccs_2  maccs_3  maccs_4  maccs_5  maccs_6  maccs_7  maccs_8  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   maccs_9  maccs_10  ...  maccs_158  maccs_159  maccs_160  maccs_161  \\\n",
       "0        0         0  ...          1          1          0          1   \n",
       "1        0         0  ...          0          0          0          1   \n",
       "2        0         0  ...          0          0          1          0   \n",
       "3        0         0  ...          1          0          0          1   \n",
       "4        0         0  ...          1          0          0          1   \n",
       "\n",
       "   maccs_162  maccs_163  maccs_164  maccs_165  maccs_166     gap  \n",
       "0          0          1          1          1          0  0.2561  \n",
       "1          1          0          0          1          0  0.1526  \n",
       "2          0          1          1          1          0  0.2286  \n",
       "3          1          0          1          1          0  0.1958  \n",
       "4          0          0          0          1          0  0.2864  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "instant-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = data.drop(['gap'], axis = 1), data['gap']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cross-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vietnamese-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:39,472]\u001b[0m A new study created in memory with name: no-name-23e4f05c-ffb2-4028-8529-9443c34f3334\u001b[0m\n",
      "\u001b[32m[I 2021-03-05 21:52:39,648]\u001b[0m Trial 0 finished with value: 0.12262049044584077 and parameters: {'n_estimators': 575, 'max_depth': 20, 'learning_rate': 0.07570624006261806, 'subsample': 0.9123603661838464, 'colsample_bytree': 0.5507663570509362, 'gamma': 3}. Best is trial 0 with value: 0.12262049044584077.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:39,832]\u001b[0m Trial 1 finished with value: 0.15091203367359993 and parameters: {'n_estimators': 417, 'max_depth': 10, 'learning_rate': 0.053363380896637905, 'subsample': 0.8505028742725644, 'colsample_bytree': 0.7628612487682878, 'gamma': 8}. Best is trial 1 with value: 0.15091203367359993.\u001b[0m\n",
      "\u001b[32m[I 2021-03-05 21:52:40,033]\u001b[0m Trial 2 finished with value: 0.12093314150535892 and parameters: {'n_estimators': 422, 'max_depth': 16, 'learning_rate': 0.07722130459346976, 'subsample': 0.8904801121544121, 'colsample_bytree': 0.761884539615871, 'gamma': 8}. Best is trial 1 with value: 0.15091203367359993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:40,156]\u001b[0m Trial 3 finished with value: 0.21573505322913472 and parameters: {'n_estimators': 442, 'max_depth': 18, 'learning_rate': 0.01605418424822754, 'subsample': 0.5289205573693312, 'colsample_bytree': 0.5590611031962702, 'gamma': 2}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:40,291]\u001b[0m Trial 4 finished with value: 0.18182159619871976 and parameters: {'n_estimators': 587, 'max_depth': 14, 'learning_rate': 0.03382137136545998, 'subsample': 0.7085055224065627, 'colsample_bytree': 0.5231890105565586, 'gamma': 9}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n",
      "\u001b[32m[I 2021-03-05 21:52:40,488]\u001b[0m Trial 5 finished with value: 0.12649019672880185 and parameters: {'n_estimators': 434, 'max_depth': 15, 'learning_rate': 0.06848378544212519, 'subsample': 0.874807019109507, 'colsample_bytree': 0.670562724023281, 'gamma': 0}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:40,761]\u001b[0m Trial 6 finished with value: 0.18582296711954935 and parameters: {'n_estimators': 592, 'max_depth': 18, 'learning_rate': 0.031565065587690774, 'subsample': 0.6398174755199284, 'colsample_bytree': 0.6364250818095577, 'gamma': 4}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n",
      "\u001b[32m[I 2021-03-05 21:52:40,944]\u001b[0m Trial 7 finished with value: 0.13390489506909603 and parameters: {'n_estimators': 484, 'max_depth': 15, 'learning_rate': 0.06622120298696631, 'subsample': 0.5728107263931106, 'colsample_bytree': 0.5957017214172236, 'gamma': 4}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:52:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:41,109]\u001b[0m Trial 8 finished with value: 0.12242863501171654 and parameters: {'n_estimators': 429, 'max_depth': 20, 'learning_rate': 0.07587177855847219, 'subsample': 0.6945884889375569, 'colsample_bytree': 0.54287868358516, 'gamma': 10}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-05 21:52:41,384]\u001b[0m Trial 9 finished with value: 0.10319126448431772 and parameters: {'n_estimators': 510, 'max_depth': 12, 'learning_rate': 0.09514037750924906, 'subsample': 0.854359637634585, 'colsample_bytree': 0.8969471623216986, 'gamma': 3}. Best is trial 3 with value: 0.21573505322913472.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.21573505322913472, params {'n_estimators': 442, 'max_depth': 18, 'learning_rate': 0.01605418424822754, 'subsample': 0.5289205573693312, 'colsample_bytree': 0.5590611031962702, 'gamma': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, label = y_valid)\n",
    "\n",
    "# define objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, .1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.50, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.50, 1),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 10),\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "\n",
    "    clf = xgb.train(params, dtrain)\n",
    "    y_pred = clf.predict(dvalid)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "    return rmse\n",
    "                                                        \n",
    "# optuna optimize\n",
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "    \n",
    "print('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "    \n",
    "# classifier\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'reg:squarederror'\n",
    "clf = xgb.XGBRegressor()\n",
    "    \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "similar-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01574441079742409\n",
      "0.01168375595381411\n",
      "0.8931247241501626\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "arabic-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my-rdkit-env] *",
   "language": "python",
   "name": "conda-env-my-rdkit-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
